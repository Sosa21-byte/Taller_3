
# ğŸ“˜ **Segmentador de Equipos ElectrÃ³nicos â€“ Streamlit + MediaPipe + Docker**

Este proyecto implementa un sistema de **segmentaciÃ³n en vivo** usando:

* **MediaPipe Selfie Segmentation**
* **Streamlit**
* **Python 3.10**
* **Docker**

El sistema abre la **cÃ¡mara del navegador** y segmenta en azul la imagen capturada.
Adicionalmente, etiqueta el objeto mostrado frente a la cÃ¡mara como:

* MultÃ­metro
* Osciloscopio
* Raspberry Pi
* Usuario

(la clasificaciÃ³n es simulada segÃºn requerimientos del laboratorio).

---

# ğŸ“‚ **Estructura del Proyecto**

```
segmentador_equipos/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ Dockerfile
```

---

# ğŸ§  **1. Archivo `app.py`**

```python
import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
from PIL import Image
import io

st.title("Segmentador en Vivo de Equipos ElectrÃ³nicos")

st.write("Activa la cÃ¡mara y coloca un multÃ­metro, osciloscopio o Raspberry Pi frente a ella.")

# Inicializar MediaPipe
mp_seg = mp.solutions.selfie_segmentation
segmentador = mp_seg.SelfieSegmentation(model_selection=1)

# SimulaciÃ³n de clasificaciÃ³n
CLASES = {
    "multimetro": "MultÃ­metro Detectado",
    "osciloscopio": "Osciloscopio Detectado",
    "raspberry": "Raspberry Pi Detectada"
}

# Entrada por cÃ¡mara del navegador
frame = st.camera_input("Activar cÃ¡mara")

if frame:
    # Convertir imagen recibida
    img_bytes = frame.getvalue()
    image = Image.open(io.BytesIO(img_bytes)).convert("RGB")
    image_np = np.array(image)

    # Procesar segmentaciÃ³n
    resultado = segmentador.process(image_np)
    mask = resultado.segmentation_mask
    mask_uint8 = (mask * 255).astype(np.uint8)

    # Crear tinte azul
    blue = np.zeros_like(image_np)
    blue[:, :, 2] = 255

    mask_3c = cv2.cvtColor(mask_uint8, cv2.COLOR_GRAY2BGR)
    mask_norm = mask_3c.astype(float) / 255

    # Mezclar manualmente
    segmented = image_np * (1 - 0.4 * mask_norm) + blue * (0.4 * mask_norm)
    segmented = segmented.astype(np.uint8)

    # Simular clasificaciÃ³n
    etiqueta = np.random.choice(list(CLASES.keys()))

    st.image(segmented, caption="Imagen Segmentada", use_column_width=True)

    st.subheader(f"Etiqueta Detectada: {CLASES[etiqueta]}")
```

---

# ğŸ§¾ **2. Archivo `requirements.txt`**

```
streamlit==1.36.0
mediapipe==0.10.14
opencv-python-headless==4.8.1.78
numpy==1.26.4
Pillow==10.2.0
```

---

# ğŸ³ **3. Archivo `Dockerfile`**

```dockerfile
FROM python:3.10-slim

WORKDIR /app

COPY requirements.txt .

RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 8501

CMD ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

---

# ğŸš€ **CÃ³mo Ejecutarlo**

## âœ… 1. Construir la imagen

En la carpeta del proyecto:

```
docker build -t segmentador:v1 .
```

## âœ… 2. Ejecutar el contenedor

```
docker run -p 8501:8501 segmentador:v1
```

## âœ… 3. Abrir la aplicaciÃ³n

Ir al navegador y abrir:

```
http://localhost:8501
```

Permitir acceso a la cÃ¡mara del navegador cuando Streamlit lo solicite.

---

# ğŸ¥ **CÃ³mo usarlo**

1. Marca la casilla **Activar cÃ¡mara**
2. Permite acceso a la cÃ¡mara del navegador
3. Coloca frente a la cÃ¡mara:

   * un **multÃ­metro**,
   * una **raspberry**,
   * o un **osciloscopio** (puede ser la foto en tu celular)
   * incluso el **Usuario**
4. El sistema:

   * Segmenta en azul
   * Muestra la etiqueta detectada

---


# ğŸ‰ Resultados

![Imagen de WhatsApp 2025-11-16 a las 23 14 53_7906c83d](https://github.com/user-attachments/assets/4bd3f743-0d8b-4a33-b509-76ddf4cf75f5)
![Imagen de WhatsApp 2025-11-16 a las 23 15 54_2e743dfe](https://github.com/user-attachments/assets/40feefc4-4146-43be-9ab8-9fe82a489d1d)
![Imagen de WhatsApp 2025-11-16 a las 23 17 14_e6aec084](https://github.com/user-attachments/assets/77a9c15c-9d0a-4a50-9cc1-32fd00911232)

